---
title: "Homework 3"
author: "Wayne Monical wem2121"
date: "2024-10-10"
output: github_document
---

## Problem 1

```{r}
library(tidyverse)
library(p8105.datasets)
data("ny_noaa")
```


The `ny_noaa` data set has `r ncol(ny_noaa)` columns and `r nrow(ny_noaa)` rows. Each observation comes with an ID given by the `id` variable. Each observation has a date, along with several precipitation and temperature measurements. 



We begin with data cleaning by creating separate numeric variables for year, month, and day. 

```{r}
ny_noaa=
  ny_noaa |> 
  mutate(
    year = ny_noaa |> pull(date) |> year(),
    month= ny_noaa |> pull(date) |> month(),
    day= ny_noaa |> pull(date) |> day()
  )
```

Using these new variables, we find that we have observations from `r min(pull(ny_noaa, year))` to `r max(pull(ny_noaa, year))`.



Ensure observations for temperature, precipitation, and snowfall are given in reasonable units. For snowfall, what are the most commonly observed values? Why?


Looking at the data's description at https://p8105.com/dataset_noaa.html, we can find that the precipitation is given in tenths of millimeters, snowfall and snow depth are given in millimeters, and maximum and minimum temperature are given in tenths of degrees Celsius. Therefore we can adjust the columns to make each column in whole millimeters or whole degrees Celsius. 
```{r}
ny_noaa = 
  ny_noaa |> 
  mutate(
    prcp = ny_noaa$prcp / 10,
    tmin = as.numeric(ny_noaa$tmin) / 10,
    tmax = as.numeric(ny_noaa$tmax) / 10)
```

There is also a single observation with negative snowfall, with ID USC00307400 on June 15th, 2005. 
```{r}
ny_noaa |> filter(snow < 0)
```

Given that New York typically does not receive snowfall in June, this value is likely meant to be zero. However, the temperature values are both within two standard deviations of the average temperature for June, so I do not believe that this observation need be thrown out. 

```{r}
ny_noaa |> 
  filter(month == 6) |> 
  drop_na(tmin, tmax) |> 
  summarise(
    mean_june_tmin = mean(tmin),
    sd_june_tmin = sd(tmin),
    mean_june_tmax = mean(tmax),
    sd_june_tmax = sd(tmax))
```
```{r}
ny_noaa =
  ny_noaa |> 
  mutate(snow = ifelse(id == 'USC00307400', 0, snow))
```


However, even after correcting the units to millimeters, the daily precipitation, snowfall, and snow depth have overly large maximum values. The maximum snowfall for New York City was recorded as 693 millimeters on January 23, 2016 according to [this website](https://www.currentresults.com/Yearly-Weather/USA/NY/New-York-City/extreme-annual-new-york-city-snowfall.php).
```{r}
ny_noaa |> 
  select(prcp, snow, snwd) |> 
  summary()
```


The most common values for snowfall are zero, 25, 13, and 51. I suspect that this is because they are converting from inches and rounding to the nearest millimeter. This is because there are 25.4 millimeters in an inch. So half of one inch corresponds to 13 millimeters, one inch corresponds to 25 millimeters, and two inches corresponds to 51 millimeters, which we see are the most common values. 

```{r}
ny_noaa |> 
  count(snow) |> 
  arrange(desc(n)) |> 
  head(5)
```
Below I have made two graphs comparing the daily maximum temperature to the minimum temperature. The first graph is a two dimensional histogram. We can see that there may be a positive relationship between minimum and maximum temperature. 

```{r}
ny_noaa |> 
  drop_na(tmin, tmax) |> 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_bin_2d()
```

The next graph is a histogram faceted based on temperature statistic: minimum or maximum. It allows us to compare the two populations, but we have lost the information on which readings are on the same day. 
```{r}
ny_noaa |> 
  drop_na(tmin, tmax) |> 
  pivot_longer(
    cols = c('tmin', 'tmax'),
    names_to = 'temp_stat',
    values_to = 'temp_value') |> 
  ggplot(aes(x = temp_value)) +
  facet_grid(temp_stat~.)+
  geom_histogram()
```


Next we create a plot showing the distribution of snowfall values greater than 0 millimeters and less than 100 millimeters in yeas of 2001 to 2004. 

```{r}
ny_noaa |> 
  filter(
    snow > 0,
    snow < 100,
    year %in% c(2001, 2002, 2003, 2004)
    ) |> 
  ggplot(aes(x = snow)) + 
  geom_histogram() + 
  facet_grid(rows = year~.)
```


## Problem 2

Here we load the data. The acceleration data comes in a wide format. We pivot the data to be longer in order to tidy it. We also transform the minute data to be numeric. We import the covariates data set and find that it is already tidy. 
```{r}
accel = 
  read_csv('data/nhanes_accel.csv') |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = min1:min1440,
    names_to = 'minute',
    names_prefix = 'min',
    values_to = 'acceleration'
  ) |> 
  mutate(minute = as.numeric(minute))

covar = 
  read_csv('data/nhanes_covar.csv', skip = 4) |> 
  janitor::clean_names()
```


We check for missing data, and find the ID for each individual, `seqn1`, agrees. 
```{r}
anti_join(covar, accel)
```

Finally, we join together the data, and filter for participants of at least 21 years of age, full demographic data, and encode the qualitative variables as character strings

```{r}
nhanes = 
  inner_join(covar, accel) |> 
  filter(age >= 21) |> 
  drop_na(sex, age, bmi, education) |> 
  mutate(
    sex = if_else(sex == 1, 'male', 'female'), 
    
  )
```



```{r}
nhanes
```


```{r}

```



